{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IDF with normal Bayes\n",
    "estimator1=[('CV',CountVectorizer(analyzer=text_process)),('Tfidf',TfidfTransformer()),('Final Analysis',MultinomialNB())]\n",
    "\n",
    "pipe1=Pipeline(estimator1)\n",
    "\n",
    "pipe1.fit(data_train,sentiment_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1=pipe1.predict(data_test)\n",
    "print(classification_report(sentiment_test,predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(sentiment_test,predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame()\n",
    "df1['actual']=sentiment_test\n",
    "df1['predicted']=predict1\n",
    "df1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.sum(sentiment_test == predict1)\n",
    "\n",
    "print(\"The accuracy with IDF using Naive Beyas:\",count/len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IDF with random forest\n",
    "estimator2=[('CV',CountVectorizer(analyzer=text_process)),('Tfidf',TfidfTransformer()),\n",
    "            ('Final Analysis',RandomForestClassifier())]\n",
    "\n",
    "pipe2=Pipeline(estimator2)\n",
    "\n",
    "pipe2.fit(data_train,sentiment_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2=pipe2.predict(data_test)\n",
    "print(classification_report(sentiment_test,predict2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(sentiment_test,predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame()\n",
    "df2['actual']=sentiment_test\n",
    "df2['predicted']=predict2\n",
    "df2.head(15)\n",
    "count = np.sum(sentiment_test == predict2)\n",
    "\n",
    "print(\"The accuracy with IDF using Naive Beyas:\",count/len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beyas without IDF\n",
    "estimator3=[('CV',CountVectorizer(analyzer=text_process)),('Tfidf',TfidfTransformer(use_idf=False)),\n",
    "            ('Final Analysis',MultinomialNB())]\n",
    "pipe3=Pipeline(estimator3)\n",
    "pipe3.fit(data_train,sentiment_train)\n",
    "predict3=pipe3.predict(data_test)\n",
    "print(classification_report(sentiment_test,predict3))\n",
    "print(confusion_matrix(sentiment_test,predict3))\n",
    "df3=pd.DataFrame()\n",
    "df3['actual']=sentiment_test\n",
    "df3['predicted']=predict3\n",
    "\n",
    "count = np.sum(sentiment_test == predict3)\n",
    "\n",
    "print(\"The accuracy without IDF using Naive Beyas:\",count/len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Forest Classifier\n",
    "estimator4=[('CV',CountVectorizer(analyzer=text_process)),('Tfidf',TfidfTransformer(use_idf=False)),\n",
    "            ('Final Analysis',RandomForestClassifier())]\n",
    "pipe4=Pipeline(estimator4)\n",
    "pipe4.fit(data_train,sentiment_train)\n",
    "predict4=pipe4.predict(data_test)\n",
    "print(classification_report(sentiment_test,predict4))\n",
    "print(confusion_matrix(sentiment_test,predict4))\n",
    "df4=pd.DataFrame()\n",
    "df4['actual']=sentiment_test\n",
    "df4['predicted']=predict4\n",
    "df4.head(15)\n",
    "count = np.sum(sentiment_test == predict4)\n",
    "\n",
    "print(\"The accuracy with IDF using Naive Beyas:\",count/len(df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Cloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "def one_sentence(data):\n",
    "    msg=' '.join(data)\n",
    "    return msg\n",
    "def join_all(data):\n",
    "    msg = \" \"\n",
    "    for i in data:\n",
    "        msg = msg + i\n",
    "    return msg\n",
    "full_data=full_data.apply(text_process)\n",
    "full_data=full_data.apply(one_sentence)\n",
    "whole=join_all(full_data)\n",
    "#whole\n",
    "plt.figure(figsize=(18,10))\n",
    "wordcloud=WordCloud(background_color='white').generate(whole)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
