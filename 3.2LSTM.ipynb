{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dropout\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in train['Corpus']:\n",
    "    lines.append(line)\n",
    "    \n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, lower=True) # Number of words to consider as features\n",
    "tokenizer.fit_on_texts(train['Corpus'].values)\n",
    "wordIndex = len(tokenizer.word_index) + 1\n",
    "print('Found %s unique tokens.' % (wordIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = tokenizer.texts_to_sequences(train['Corpus'].values)\n",
    "XTrain = pad_sequences(XTrain, maxlen=30) # Cuts off the texts after this number of words\n",
    "\n",
    "XTest = tokenizer.texts_to_sequences(test['Corpus'].values)\n",
    "XTest = pad_sequences(XTest, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape, XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = to_categorical(train['Sentiment'], 3)\n",
    "yTest = to_categorical(test['Sentiment'], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= models.Sequential()\n",
    "model.add(layers.Embedding(wordIndex, 128, input_length=1000))\n",
    "model.add(layers.LSTM(200))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(XTrain ,yTrain, batch_size=250, epochs=100, validation_split=0.2,\n",
    "         callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "valAccuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "valLoss = history.history['val_loss']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10,10))\n",
    "plot = ax1.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n",
    "ax1.plot(epochs, valAccuracy, 'b', label='Validation Accuracy')\n",
    "ax1.set(title='Training/Validation Accuracy', ylabel='Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "plot = ax2.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "ax2.plot(epochs, valLoss, 'b', label='Validation Loss')\n",
    "ax2.set(title='Training/Validation Loss', ylabel='Loss', xlabel='Epochs')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('Loss/Accuracy of the LSTM Sentiment Classifier', fontsize=16, fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(yTest, 1), model.predict_classes(XTest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
